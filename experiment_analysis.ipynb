{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c33282ac",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "This script recreates the plots and tables of the experimental evaluation in the paper.\n",
    "By default it assumes that the data is stored in the directory:\n",
    "- `experimental_results/simulation_collection/` for the Finite Horizon setting and \n",
    "- `experimental_results/simulation_collection_period/` for the Periodic setting.\n",
    "\n",
    "To reproduce all plots, simply run: `reproduce_experiments()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools, os\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import scipy as sci\n",
    "from scipy.stats import binom\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "from matplotlib.axes._axes import Axes\n",
    "from matplotlib.markers import MarkerStyle\n",
    "from seaborn import color_palette\n",
    "from numpy import ndarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257117fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataSet:\n",
    "    \n",
    "    def __init__(self, period=1, name=None, og_data=None, setting=None, data=None, base_path=None):\n",
    "        self.METRICS = ['dp',\"acc_cost\",\"acc_util\", \"n_interventions\"]\n",
    "        if base_path is not None:\n",
    "            self.base_path = base_path\n",
    "        elif period==1:\n",
    "            self.base_path =  \"experimental_results/simulation_collection/\"\n",
    "        else:\n",
    "            self.base_path =  \"experimental_results/simulation_collection_period/\"\n",
    "        self.base_parameter = [\"fairness\", \"dataset\",\"sensitive_attr\",\"ml_algo\",\"time_horizon\",\n",
    "                               \"cost_type\",\"n_cost_bin\",\n",
    "                           \"threshold\",\"lambda_decision\", \"composition_type\", \"periods\"]\n",
    "        self.base_types = {\"fairness\": str, \"dataset\": str, \"sensitive_attr\": str, \"ml_algo\": str,\n",
    "                           \"time_horizon\": int, \"cost_type\": str, \"n_cost_bin\": int,\n",
    "                           \"threshold\": self.thresh, \"lambda_decision\": float, \"composition_type\": str, \n",
    "                           \"periods\": int}\n",
    "        \n",
    "        \n",
    "        self.colmap = {\"fair_val\": \"Bias\", \"shield\":\"Shield\", \"step\":\"Step\", \"value_type\":\"Aggregation Method\",\n",
    "                 \"fairness\":\"Fairness Property\", \"ml_algo\":\"ML Algorithm\", \"acc_cost\":\"Accumulated Cost\",\n",
    "                      \"diff_util\":\"Utility Loss\", \"environment\":\"Environment\", \"threshold\":\"Threshold\",\n",
    "                      \"ass_viol\": \"Assumption Violated\", \"fair_viol\":\"Fairness Violation\", \"period\":\"Period\"} \n",
    "        self.shieldmap = {\"none\":\"No Shield\", \"naive\":\"Static-Fair\", \n",
    "                     \"bounded_acc_rates\":\"Static-BW\",\"buffered\":\"Dynamic\" }\n",
    "        self.fairmap = {\"dp\":\"DP\", \"eo\":\"EqOpp\"}\n",
    "        self.mlmap = {\"diffdp\":\"DiffDP\", \"erm\":\"ERM\", \"hsic\":\"HSIC\", \"laftr\":\"LAFTR\", \"pr\":\"PRemover\"}\n",
    "\n",
    "        self.name = name\n",
    "        self.data_set = self.data_sets(name)\n",
    "        self.og_data = og_data\n",
    "        self.setting = setting\n",
    "        if data is None and setting is not None and og_data is not None:\n",
    "            self.data = self.post_process()\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.period=period\n",
    "        \n",
    "    def rename_data(self, data= None):\n",
    "        if data is None:\n",
    "            data = self.data.copy()\n",
    "        data[\"shield\"] = data[\"shield\"].apply(lambda x : self.shieldmap[x])\n",
    "        data[\"fairness\"] = data[\"fairness\"].apply(lambda x : self.fairmap[x])\n",
    "        data[\"ml_algo\"] = data[\"ml_algo\"].apply(lambda x : self.mlmap[x])\n",
    "        data = data.rename(columns=self.colmap)\n",
    "        return data\n",
    "        \n",
    "    def true_name(self, col):\n",
    "        return self.colmap[col]\n",
    "    \n",
    "        \n",
    "    def get_single_data(self, data=None):\n",
    "        if data is not None:\n",
    "            self.single_data = data[data[\"periods\"]==1]\n",
    "            return self.single_data.copy()\n",
    "        elif self.data is not None:\n",
    "            self.single_data = self.data[self.data[\"periods\"]==1]\n",
    "            return self.single_data.copy()\n",
    "        else:\n",
    "            return None\n",
    "        return None\n",
    "\n",
    "    def process_comp_name(self, file_name):\n",
    "        name = file_name.split(\"_composable_\")\n",
    "        name1 = self.process_single_name(name[0])\n",
    "        name2 = name[1].replace(\".csv\", \"\")\n",
    "        name2 = name2.rsplit(\"_\", 1)\n",
    "       \n",
    "        fin_name = [self.base_types[self.base_parameter[i]](v) for i, v in enumerate(name1 + name2)]\n",
    "        return fin_name\n",
    "\n",
    "    def process_single_name(self, file_name):\n",
    "        name = file_name.split(\"_\")\n",
    "        name[-1] = name[-1].replace(\".csv\", \"\")\n",
    "        if name[0]!=\"eo\":\n",
    "            name = [\"dp\"] + name\n",
    "        if name[1] == \"bank\":\n",
    "            name = [name[0]] + name[1:2] + name[3:]\n",
    "        return name\n",
    "\n",
    "    def data_sets(self, name):\n",
    "        if name is None:\n",
    "            return {\"path\":  self.base_path.format(),\n",
    "                      \"parameter\": self.base_parameter,\n",
    "                      \"parse_foo\": self.process_comp_name}\n",
    "    \n",
    "    def thresh(self, val):\n",
    "        return float(val)/10000\n",
    "    \n",
    "    def load_setting(self):\n",
    "        if self.setting is None:\n",
    "            file_dir = self.data_set[\"path\"]\n",
    "            param_names = self.data_set[\"parameter\"]\n",
    "            parse_name_foo = self.data_set[\"parse_foo\"]\n",
    "            file_names = os.listdir(file_dir)\n",
    "            all_dfs = []\n",
    "            run_id = 0\n",
    "            setting_id = 0\n",
    "            data = [parse_name_foo(file_name) for file_name in file_names if \".csv\" in file_name]\n",
    "            df = pd.DataFrame(data, columns=param_names)\n",
    "            combs = list(itertools.product(*[list(df[c].unique()) for c in df.columns]))\n",
    "            df = pd.DataFrame(combs, columns=param_names).reset_index().rename(\n",
    "                columns={\"index\": \"setting_id\",\"dp\": \"fair_val\"})\n",
    "            df[\"shield\"] = df[\"composition_type\"]\n",
    "            df.loc[df[\"sensitive_attr\"]==\"sex\", \"sensitive_attr\"] = \"gender\"\n",
    "            df[\"environment\"] = df[\"dataset\"] + \", \" + df[\"sensitive_attr\"]\n",
    "            self.setting = df\n",
    "            \n",
    "        return self.setting.copy()\n",
    "       \n",
    "    def clean_data(self, df):\n",
    "        fair = df[\"fairness\"].unique()[0]\n",
    "        for g in [\"A\",\"B\"]:\n",
    "            for k in [\"seen\", \"acc\"]:\n",
    "                if fair==\"eo\":\n",
    "                    df[f\"g{g}{k}1\"] = df[f\"g{g}{k}\"]\n",
    "                    df[f\"g{g}{k}\"] = df[f\"g{g}{k}0\"] + df[f\"g{g}{k}1\"]\n",
    "                if fair==\"dp\":\n",
    "                    for n in [\"0\",\"1\"]:\n",
    "                        df[f\"g{g}{k}{n}\"] = np.NaN            \n",
    "        return df\n",
    "\n",
    "    def load_data(self):\n",
    "        if self.og_data is None:\n",
    "            file_dir = self.data_set[\"path\"]\n",
    "            param_names = self.data_set[\"parameter\"]\n",
    "            parse_name_foo = self.data_set[\"parse_foo\"]\n",
    "            file_names = os.listdir(file_dir)\n",
    "            all_dfs = []\n",
    "            run_id = 0\n",
    "            for file_name in tqdm.tqdm(file_names):\n",
    "                if \".csv\" in file_name:\n",
    "                    name = parse_name_foo(file_name)\n",
    "                    file_path = os.path.join(file_dir, file_name)\n",
    "                    tmp_df = pd.read_csv(file_path, index_col=0)\n",
    "                    #tmp_df[\"setting_name\"] = \", \".join(name)\n",
    "                    tmp_df[\"run_id\"] = tmp_df[\"sim_num\"] + run_id\n",
    "                    for i, v in enumerate(param_names):\n",
    "                        tmp_df[v] = name[i]\n",
    "                    if tmp_df[\"periods\"].unique() == self.period:\n",
    "                        run_id = tmp_df[\"run_id\"].max() + 1\n",
    "                        temp_df = self.clean_data(tmp_df)\n",
    "                        temp_df = temp_df.rename(columns={\"dp\": \"fair_val\"})\n",
    "                        all_dfs.append(tmp_df)\n",
    "            df = pd.concat(all_dfs, ignore_index=True)\n",
    "            self.og_data = df\n",
    "        return self.og_data.copy()\n",
    "\n",
    "    def post_process(self):\n",
    "        parameter_names = self.data_set[\"parameter\"]\n",
    "        df_og = self.og_data\n",
    "        df_og[\"ml_util\"] = (1-df_og[\"intervention\"])*df_og[\"utility\"] + df_og[\"intervention\"]*(1-df_og[\"utility\"])\n",
    "        df_og['acc_ml_util'] = df_og.groupby('run_id')[\"ml_util\"].cumsum()\n",
    "        df_og[\"diff_util\"] = df_og[\"acc_util\"]/df_og[\"acc_ml_util\"]\n",
    "        df_og.loc[df_og[\"sensitive_attr\"]==\"sex\", \"sensitive_attr\"] = \"gender\"\n",
    "        df_og = df_og[(df_og[\"lambda_decision\"].isin([0,1]))]\n",
    "        dfs = []\n",
    "        for fair in df_og[\"fairness\"].unique():\n",
    "            base_df = df_og[(df_og[\"fairness\"]==fair) & (df_og[\"composition_type\"]==\"none\")].copy()\n",
    "            for dpt in df_og[\"threshold\"].unique():\n",
    "                for cost in df_og[\"cost_type\"].unique():\n",
    "                    bdf = base_df.copy()\n",
    "                    bdf[\"fairness\"] = fair\n",
    "                    bdf[\"threshold\"] = dpt\n",
    "                    bdf[\"cost_type\"] = cost\n",
    "                    dfs.append(bdf)\n",
    "        df = pd.concat([df_og[df_og[\"composition_type\"]!=\"none\"].copy()] + dfs, ignore_index=True)\n",
    "        df = pd.merge(df, self.setting, on=parameter_names, how='left')\n",
    "        df = df.rename(columns={\"dp\": \"fair_val\"})\n",
    "        df.loc[df[\"sensitive_attr\"]==\"sex\", \"sensitive_attr\"] = \"gender\"\n",
    "        self.setting.loc[self.setting[\"sensitive_attr\"]==\"sex\", \"sensitive_attr\"] = \"gender\"\n",
    "        df[\"period\"] = (df[\"step\"])// (df[\"time_horizon\"])\n",
    "        df = df[(df[\"ml_algo\"]!=\"adv\") & (df[\"lambda_decision\"].isin([0,1]))]\n",
    "        self.data= df\n",
    "        return self.data.copy()\n",
    "    \n",
    "    def process_data(self, save_memory=False):\n",
    "        setting = self.load_setting()\n",
    "        og_data = self.load_data()\n",
    "        data = self.post_process()\n",
    "        self.check_data()\n",
    "        if save_memory:\n",
    "            self.og_data = None\n",
    "            return data, setting\n",
    "        else:\n",
    "            return data, setting, og_data\n",
    "        \n",
    "    def check_data(self):\n",
    "        dic = {}\n",
    "        inp_df = self.data.copy()\n",
    "        for v, df in inp_df.groupby(\"fairness\"):\n",
    "            max_sim= df[\"sim_num\"].max()+1\n",
    "            max_step = df[\"step\"].max() +1\n",
    "            r = df[df[\"step\"]==0].groupby(\"setting_id\").size().reset_index()\n",
    "            r = r[r[0]!=max_sim]\n",
    "            r2 = df.groupby([\"setting_id\", \"run_id\"]).size().reset_index()\n",
    "            r2 = r2[r2[0]!=max_step]\n",
    "            dic[v] = [r,r2]\n",
    "        return dic\n",
    "    \n",
    "    def comp_diff_util(self, data):\n",
    "        data[\"diff_util\"] = (data[\"acc_ml_util\"]-data[\"acc_util\"])/data[\"acc_ml_util\"]*100\n",
    "        return data\n",
    "    \n",
    "    def basic_filter(self, data):\n",
    "        return  data[data[\"cost_type\"]==\"constant\"].copy()\n",
    "    \n",
    "    def single_clean(self, agg=0, drop_none=False):\n",
    "        bdf = self.data.copy()\n",
    "        bdf = self.comp_diff_util(bdf)\n",
    "        bdf = self.basic_filter(bdf)\n",
    "        if agg == 1: \n",
    "            bdf = self.condition_on_last(bdf)\n",
    "        if agg==0:\n",
    "            bdf = self.condition_on_last(bdf)\n",
    "            bdf = bdf.groupby(\"setting_id\")[[\"diff_util\", \"fair_val\"]].mean().reset_index()\n",
    "            bdf = bdf.merge(self.setting, on=[\"setting_id\"], how=\"left\")\n",
    "        if drop_none:\n",
    "            bdf = bdf[(bdf[\"shield\"]==\"naive\")]\n",
    "        return bdf.copy()\n",
    "    \n",
    "    def multi_clean(self, agg=0, filt=True, filt_ass=False):\n",
    "        kpi = [\"ass_viol\",\"fair_viol\",\"diff_util\"]\n",
    "        bdf = self.data.copy()\n",
    "        bdf = self.comp_diff_util(bdf)\n",
    "        bdf = self.basic_filter(bdf)\n",
    "        if filt:\n",
    "            bdf = bdf[(bdf[\"shield\"]!=\"none\") & (bdf[\"ml_algo\"]==\"erm\")]\n",
    "        else:\n",
    "            bdf = bdf[(bdf[\"ml_algo\"]==\"erm\")]\n",
    "        if filt_ass:\n",
    "             bdf = bdf[(bdf[\"ass_viol\"]==0)]\n",
    "        \n",
    "        bdf = bdf[bdf[\"cost_type\"]==\"constant\"]\n",
    "        pdf = bdf.groupby([\"setting_id\",\"run_id\",\"period\"]).tail(1).copy()\n",
    "        pdf[\"fair_sat\"] = (pdf[\"fair_val\"] > pdf[\"threshold\"]).astype(int)\n",
    "        pdf = pdf.apply(self.naive_assumption, axis=1)\n",
    "        res1 = pdf.groupby([\"setting_id\",\n",
    "                           \"run_id\"])[[\"failure\", \"fair_sat\"]].max().reset_index().rename(\n",
    "            columns={\"failure\":\"ass_viol\", \"fair_sat\":\"fair_viol\"})\n",
    "        res2 = bdf.groupby([\"setting_id\", \"run_id\", \"period\"])[[\"utility\", \"ml_util\"]].sum().rename(\n",
    "            columns={\"utility\":\"p_util\", \"ml_util\":\"p_ml_util\"})\n",
    "        ndf = bdf.merge(res2, on=[\"setting_id\", \"run_id\", \"period\"], how=\"left\")\n",
    "        ndf = ndf.merge(res1, on=[\"setting_id\", \"run_id\"], how=\"left\")\n",
    "        if agg==3:\n",
    "            return ndf\n",
    "        elif agg==2:\n",
    "            return ndf.groupby([\"setting_id\", \"run_id\",\"period\"]).tail(1)\n",
    "        elif agg==1:\n",
    "            return ndf.groupby([\"setting_id\", \"run_id\"]).tail(1)\n",
    "        else: \n",
    "            #pdf = pdf.merge(res, on=[\"setting_id\", \"run_id\"], how=\"left\")\n",
    "            ndf = ndf.groupby([\"setting_id\", \"run_id\"]).tail(1)\n",
    "            #kpi = [\"ass_viol\",\"fair_viol\",\"diff_util\"]\n",
    "            res = ndf.groupby(\"setting_id\")[kpi].mean().reset_index()\n",
    "            return res.merge(self.setting, on=\"setting_id\", how=\"left\")\n",
    "    \n",
    "    \n",
    "    def get_clean_data(self, agg=0, drop_none=False, filt_ass=False):\n",
    "        if self.period==1:\n",
    "            return self.single_clean(agg, drop_none)\n",
    "        else:\n",
    "            return self.multi_clean(agg, filt=drop_none, filt_ass=filt_ass)\n",
    "            \n",
    "    \n",
    "    def condition_on_last(self, data=None):\n",
    "        if data is None:\n",
    "            return self.data.groupby([\"setting_id\",\"run_id\"]).tail(1).copy()\n",
    "        return data.groupby([\"setting_id\",\"run_id\"]).tail(1).copy()\n",
    "    \n",
    "    def naive_assumption(self, x):\n",
    "        if x[\"shield\"]==\"naive\":\n",
    "            if x[\"fairness\"] == \"dp\":\n",
    "                x[\"failure\"] = int(x[\"gAseen\"]!=x[\"gBseen\"])\n",
    "            elif x[\"fairness\"] == \"eo\":\n",
    "                x[\"failure\"] = int(x[\"gAseen1\"]!=x[\"gBseen1\"])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyse:\n",
    "    \n",
    "    def __init__(self, base_path=None, data_single=None, data_multi=None):\n",
    "        plt.rcParams['text.usetex'] = True\n",
    "        plt.rcParams['font.family'] = 'serif'\n",
    "        plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "        if base_path is None:\n",
    "            self.base_path = \"experimental_results/graphs/paper\"\n",
    "        else:\n",
    "            self.base_path =  base_path\n",
    "           \n",
    "        os.makedirs(self.base_path, exist_ok=True)\n",
    "        self.data_single = data_single\n",
    "        self.data_multi = data_multi\n",
    "        \n",
    "        \n",
    "    def load_data(self):\n",
    "        if self.data_single is None:\n",
    "            self.data_single = DataSet(period=1)\n",
    "            self.data_single.process_data()\n",
    "        if self.data_multi is None:\n",
    "            self.data_multi = DataSet(period=10)\n",
    "            self.data_multi.process_data()\n",
    "        \n",
    "    def process_single(self):\n",
    "        if self.data_single is None:\n",
    "            self.data_single = DataSet(period=1)\n",
    "            self.data_single.process_data()\n",
    "        self.single_cost_util()\n",
    "        self.single_fairness_value_distribution()\n",
    "        self.single_comp_conditional_utility_box()\n",
    "        self.single_comp_conditional_utility_kde()\n",
    "        \n",
    "    def process_multi(self):\n",
    "        if self.data_multi is None:\n",
    "            self.data_multi = DataSet(period=10)\n",
    "            self.data_multi.process_data()\n",
    "        self.multi_fail_rates()\n",
    "        self.multi_period_cost_decrease()\n",
    "        self.multi_fairness_value_distribution_box(False)\n",
    "        self.multi_fairness_value_distribution_box(True)\n",
    "        self.multi_papter_temp_both()\n",
    "        \n",
    "            \n",
    "    def process_both(self):\n",
    "        self.process_single()\n",
    "        self.process_multi()\n",
    "        self.both_heat_comp()\n",
    "        \n",
    "\n",
    "    \n",
    "    def process_paper(self):\n",
    "        if self.data_single is None:\n",
    "            self.data_single = DataSet(period=1)\n",
    "            self.data_single.process_data()\n",
    "        if self.data_multi is None:\n",
    "            self.data_multi = DataSet(period=10)\n",
    "            self.data_multi.process_data()\n",
    "        self.both_heat_comp()\n",
    "        self.multi_papter_temp_both()\n",
    "        self.multi_fail_rates()\n",
    "        \n",
    "        \n",
    "    def single_heat_comparison_data(self):\n",
    "        #bdf = single_clean(df)\n",
    "        bdf = self.data_single.get_clean_data(agg=0, drop_none=True)\n",
    "        data = {}\n",
    "        for g in bdf.groupby([\"threshold\"]):\n",
    "            thr = g[0]\n",
    "            for i, gs in enumerate(g[1].groupby(\"fairness\")):\n",
    "                fair = gs[0]\n",
    "                pdf = gs[1]\n",
    "                data[thr,fair]= pdf.pivot(index=\"environment\", columns=\"ml_algo\", values=\"diff_util\").sort_index()\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    ### Plot Fig. 4\n",
    "    def single_cost_util(self):\n",
    "        bdf = self.data_single.get_clean_data(agg=1, drop_none=True)\n",
    "        bdf = bdf[bdf[\"shield\"]!=\"none\"]\n",
    "        bdf = self.data_single.rename_data(bdf)\n",
    "        rn = self.data_single.true_name\n",
    "        sns.lmplot( data=bdf, x=rn(\"acc_cost\"),  y=rn(\"diff_util\"), hue=rn(\"environment\"), row=rn(\"threshold\"), col=rn(\"fairness\"),\n",
    "                   scatter_kws={'alpha':0.1, \"s\":5}, facet_kws={'sharey': False, 'sharex': False}, aspect=1.2)\n",
    "        plt.savefig(os.path.join(self.base_path, \"single_corr_cost_util.pdf\"),\n",
    "                        bbox_inches='tight', pad_inches=0.1)\n",
    "   \n",
    "    # Plot Fig 6 and 7\n",
    "    def single_comp_conditional_utility_box(self):\n",
    "        bdf = self.data_single.get_clean_data(agg=1, drop_none=True)\n",
    "        pdf = self.data_single.rename_data(bdf)\n",
    "        rn = self.data_single.true_name\n",
    "        sns.catplot(kind=\"boxen\",data=pdf, y=rn(\"diff_util\"),   x=rn(\"threshold\") ,hue=rn(\"ml_algo\"), col=rn(\"fairness\"),\n",
    "                   sharey=False, sharex=False, showfliers=False) \n",
    "        plt.savefig(os.path.join(self.base_path, f\"single_utilit_distr_mlalgo_box.pdf\"),  bbox_inches='tight', pad_inches=0.1)\n",
    "        sns.catplot(kind=\"boxen\",data=pdf, y=rn(\"diff_util\"),   x=rn(\"threshold\") ,hue=rn(\"environment\"), col=rn(\"fairness\"),\n",
    "                   sharey=False, sharex=False, showfliers=False) \n",
    "        plt.savefig(os.path.join(self.base_path, f\"single_utilit_distr_enviornment_box.pdf\"),  bbox_inches='tight', pad_inches=0.1)\n",
    "        \n",
    "        \n",
    "    # Plot Fig. 5 and Tab. 9\n",
    "    def single_fairness_value_distribution(self):\n",
    "        bdf = self.data_single.get_clean_data(agg=1, drop_none=False)\n",
    "        bdf[\"Normalised Fairness\"] = bdf[\"fair_val\"] / bdf[\"threshold\"]\n",
    "        bdf[\"Violated\"] = bdf[\"Normalised Fairness\"] > 1\n",
    "        #bdf = bdf[bdf[\"shield\"]==\"none\"]\n",
    "        pbdf = self.data_single.rename_data(bdf)\n",
    "        rn = self.data_single.true_name\n",
    "        g = sns.displot(kind=\"hist\", data=pbdf, x=\"Normalised Fairness\",hue=rn(\"fairness\"), col=rn(\"shield\"), \n",
    "                        facet_kws={'sharey': False, 'sharex': False},\n",
    "                        element=\"step\", stat=\"percent\", binwidth=0.1)\n",
    "        shield = [\"naive\", \"none\"]\n",
    "        fair = {\"dp\":\"blue\", \"eo\":\"orange\"}\n",
    "        for i, ax in enumerate(g.axes.flat):\n",
    "            for fa, cfa in fair.items():\n",
    "                meanf = bdf[(bdf[\"fairness\"]==fa) & (bdf[\"shield\"]==shield[i])][\"Normalised Fairness\"].mean()\n",
    "                ax.axvline(x=meanf, color=cfa, linestyle='--')\n",
    "            if i==0:\n",
    "                ax.set_ylim(0,10)\n",
    "                ax.set_xlim(0,2)\n",
    "            ax.axvline(x=1, color='red', linestyle='--')\n",
    "        plt.savefig(os.path.join(self.base_path,\"violation_distr.pdf\"),\n",
    "                        bbox_inches='tight', pad_inches=0.1)\n",
    "        latex_df = pbdf.round(2).groupby([rn(\"fairness\"),rn(\"shield\")])[\"Normalised Fairness\"].agg(\n",
    "                QL25=lambda x: x.quantile(0.25),\n",
    "                Median=lambda x: x.quantile(0.5),\n",
    "                QL75=lambda x: x.quantile(0.75),\n",
    "                Mean=lambda x: x.mean(),\n",
    "                Std=lambda x: x.std(),\n",
    "                Above=lambda x: (len(x[x>1])/len(x))*100)\n",
    "        print(latex_df.style.format(precision=2).to_latex())\n",
    "        return bdf\n",
    "        \n",
    "    def multi_heat_comp_data(self, filt=True):\n",
    "        bdf = self.data_multi.get_clean_data(agg=0, drop_none=True, filt_ass=filt)\n",
    "        col = bdf[\"shield\"].unique()\n",
    "        data = {}\n",
    "        for g in bdf.groupby([\"threshold\"]):\n",
    "            thr = g[0]\n",
    "            for i, gs in enumerate(g[1].groupby(\"fairness\")):\n",
    "                fair = gs[0]  \n",
    "                pdf = gs[1]\n",
    "                pdf = pdf.pivot(index=\"environment\", columns=\"shield\", values=\"diff_util\").sort_index()\n",
    "                add_col = set(col).difference(pdf.columns)\n",
    "                for c in add_col:\n",
    "                    pdf[c] = np.nan\n",
    "                pdf = pdf[sorted(pdf.columns)]\n",
    "                data[thr, fair] = pdf\n",
    "        return data\n",
    "\n",
    "    # Plot Tab. 2,10,11\n",
    "    def both_heat_comp(self):\n",
    "        data = {\"FinHzn\":self.single_heat_comparison_data(),\n",
    "                \"Periodic\": self.multi_heat_comp_data(False),\n",
    "               # \"Periodic Cond.\": multi_heat_comp_data(df2, True)\n",
    "               }\n",
    "\n",
    "        col = {\"dp\":sns.light_palette(\"seagreen\", as_cmap=True),\n",
    "               \"eo\":sns.light_palette(\"#69d\", as_cmap=True)}\n",
    "        thresh = set(self.data_single.data[\"threshold\"].unique()).intersection(self.data_multi.data[\"threshold\"].unique())\n",
    "        xorder = {\"Periodic\":[self.data_multi.shieldmap[i] for i in [\"naive\",\"bounded_acc_rates\",\"buffered\"]], \n",
    "                 \"FinHzn\":[self.data_single.mlmap[i] for i in [\"diffdp\", \"erm\", \"hsic\", \"laftr\", \"pr\"]],\n",
    "                 #\"Periodic Cond.\":[\"Static-Fair\",\"Static-BW\",\"Dynamic\"]\n",
    "                 }\n",
    "\n",
    "        xmap = {\"Periodic\":self.data_multi.shieldmap, \n",
    "                 #\"Periodic Cond.\":{\"naive\":\"Static-Fair\",\"bounded_acc_rates\":\"Static-BW\",\"buffered\":\"Dynamic\"},\n",
    "                 \"FinHzn\":self.data_single.mlmap }\n",
    "        \n",
    "        for tr in thresh:\n",
    "            fig, axs = plt.subplots(2, len(data), figsize=(15, 5), gridspec_kw={'wspace': 0.05})\n",
    "            for i,(fair,c) in enumerate(col.items()):\n",
    "                for j, (kind, dat) in enumerate(data.items()):\n",
    "                    ax = axs[i,j]\n",
    "                    pdf = data[kind][tr, fair]\n",
    "                    #pdf.index = [f\"${v}$\" for v in pdf.index]\n",
    "                    pdf = pdf.rename(columns=xmap[kind])\n",
    "                    pdf = pdf[xorder[kind]]\n",
    "                    sns.heatmap(pdf, annot=True, cmap=c, ax=ax, cbar=False, fmt=\".2f\")\n",
    "                    if i==0:\n",
    "                        ax.set_title(kind)\n",
    "                        #ax.xaxis.set_label_position(\"top\")\n",
    "                        #ax.set_xlabel(k, labelpad=10) \n",
    "                    if j !=0:\n",
    "                        ax.set_yticks([])\n",
    "                    if i != 1:\n",
    "                        ax.set_xticks([])\n",
    "                    ax.set_ylabel(\"\")\n",
    "                    ax.set_xlabel(\"\")\n",
    "                    if i ==1:\n",
    "                        if kind==\"FinHzn\":\n",
    "                            ax.set_xlabel(self.data_single.true_name(\"ml_algo\"))\n",
    "                        else:\n",
    "                            ax.set_xlabel(self.data_multi.true_name(\"shield\"))\n",
    "            plt.savefig(os.path.join(self.base_path,f\"heat_util_thr-{tr}.pdf\"),\n",
    "                        bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    # Generate Tab. 2\n",
    "    def multi_fail_rates(self):\n",
    "        bdf = self.data_multi.get_clean_data(agg=1)\n",
    "        bdf = self.data_multi.rename_data(bdf)\n",
    "        rn = self.data_multi.true_name\n",
    "        bdf[\"Fairness Satisfied\"] = 1-bdf[rn(\"fair_viol\")]\n",
    "        bdf[\"Assumption Satisfied\"] = 1-bdf[rn(\"ass_viol\")]\n",
    "        rn = self.data_multi.true_name\n",
    "        fdf = bdf.groupby([rn(\"fairness\"), rn(\"shield\")])[\"Assumption Satisfied\", \"Fairness Satisfied\"].mean()\n",
    "        #fdf[\"Conditional\"] = bdf[bdf[\"ass_viol\"]==1].groupby([\"fairness\", \"shield\"])[\"fair_sat\"].mean()\n",
    "        #for t in [0.1, 0.2]:\n",
    "        #    fdf[f\"ass_viol {t}\"] = bdf[bdf[\"threshold\"]==t].groupby([\"fairness\", \"shield\"])[\"ass_viol\"].mean().values\n",
    "        \n",
    "        print(fdf.apply(self.to_percent).style.to_latex())\n",
    "        return fdf\n",
    "    \n",
    "    # Plot Fig 8\n",
    "    def multi_period_cost_decrease(self, filt=True):\n",
    "        bdf = self.data_multi.get_clean_data(agg=2, drop_none=True)\n",
    "        kpi = [\"ass_viol\",\"fair_viol\",\"diff_util\"]\n",
    "        bdf[\"abs_util_loss\"]= bdf[\"p_ml_util\"]-bdf[\"p_util\"]\n",
    "        res = bdf.groupby([\"setting_id\", \"run_id\"]\n",
    "                         )[\"abs_util_loss\"].sum().reset_index().rename(columns={\"abs_util_loss\":\"total_util_loss\" })\n",
    "        bdf = bdf.merge(res, on=[\"setting_id\", \"run_id\"], how=\"left\")\n",
    "        bdf[\"Percentage Utility Loss\"] = bdf[\"abs_util_loss\"] / bdf[\"total_util_loss\"]*100\n",
    "        if filt:\n",
    "            bdf = bdf[(bdf[\"ass_viol\"]==0)]\n",
    "        pdf = self.data_multi.rename_data(bdf)\n",
    "        rn = self.data_multi.true_name\n",
    "        sns.catplot(kind=\"boxen\", data=pdf, hue=rn(\"period\"), y=\"Percentage Utility Loss\", x=rn(\"shield\"), \n",
    "                    col=rn(\"fairness\"), row=rn(\"threshold\"),sharey=False,showfliers=False , aspect=1.2,\n",
    "                    order=self.get_shield_order(),\n",
    "                   col_order=[self.data_multi.fairmap[\"dp\"], self.data_multi.fairmap[\"eo\"]])\n",
    "        plt.savefig(os.path.join(self.base_path,f\"multi_period_cost_decrease_cond-{filt}.pdf\"),\n",
    "                        bbox_inches='tight', pad_inches=0.1)\n",
    "        return pdf\n",
    "       \n",
    "    # Plot Fig 2\n",
    "    def multi_papter_temp_both(self):\n",
    "        plt.rcParams['text.usetex'] = True\n",
    "        plt.rcParams['font.family'] = 'serif'\n",
    "        plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "        plt.rcParams['font.size'] = 20\n",
    "        df2 = self.data_multi.data.copy()\n",
    "        fdf = df2[(df2[\"dataset\"]==\"adult\") & \n",
    "                  (df2[\"threshold\"]==0.1) &  (df2[\"sensitive_attr\"]==\"gender\") ]\n",
    "        bdf1 = self.process_temp_data(fdf)\n",
    "        bdf1 = bdf1[bdf1[\"value_type\"]!=\"min\"]\n",
    "        periods = fdf[\"periods\"].unique()[0]\n",
    "        period_len = fdf[\"time_horizon\"].unique()[0]\n",
    "\n",
    "\n",
    "        pdf1 = self.data_multi.rename_data(bdf1)\n",
    "        rn = self.data_multi.true_name\n",
    "        custom_palette = sns.color_palette(\"muted\", 6)  # Create a palette with 3 colors\n",
    "        custom_palette.pop(3)\n",
    "\n",
    "        g =sns.relplot(kind=\"line\", data=pdf1,  y=rn(\"fair_val\"), x=rn(\"step\"), hue=rn(\"shield\"), \n",
    "                        style=rn(\"value_type\"), col=rn(\"fairness\"), \n",
    "                        hue_order= [self.data_multi.shieldmap[c] for c in [\"naive\", \"bounded_acc_rates\", \"buffered\",\"none\"]] , \n",
    "                        dashes=[(2, 0),(1, 1)], palette=custom_palette,\n",
    "                        estimator=None, aspect=1.5)\n",
    "        for ax in g.axes.flat:\n",
    "            ax.axhline(y=0.1, color='red', linestyle='--')\n",
    "\n",
    "            for i in range(1,periods):\n",
    "                ax.axvline(x=i*period_len, color='#D3D3D3', linestyle=\":\")\n",
    "            #ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "            ax.set_ylim(0,0.45)\n",
    "        plt.text(-665, 0.03, rn(\"threshold\"), color='red', rotation=90)\n",
    "        plt.savefig(os.path.join(self.base_path, f\"tempplot3.pdf\"), bbox_inches='tight', pad_inches=0.1)\n",
    "    \n",
    "    def process_temp_data(self, df):\n",
    "        bdf2 = df.copy()\n",
    "        bdf2 = bdf2.groupby([\"step\",\"setting_id\"]).agg({ m :['mean', 'min', 'max'] for m in [\"fair_val\"]})\n",
    "        bdf2 = bdf2.stack().reset_index()\n",
    "        bdf2 = pd.merge(bdf2, self.data_multi.setting, on=[\"setting_id\"], how='left')\n",
    "        names = [i for i in list(bdf2.columns) if \"level_\" in i]     \n",
    "        bdf2 = bdf2.rename(columns={names[0]: \"value_type\"})\n",
    "        return bdf2\n",
    "\n",
    "    def to_percent(self, x):\n",
    "        return \"$\"+ (100*x).round(2).astype(str) + \"$\"\n",
    "    \n",
    "    def get_shield_order(self, with_none=False):\n",
    "        order = [\"naive\", \"bounded_acc_rates\", \"buffered\"]\n",
    "        if with_none:\n",
    "            order += [\"none\"]\n",
    "        return [self.data_multi.shieldmap[x] for x in order]\n",
    "\n",
    "    # Plot Fig 9 and 10\n",
    "    def multi_fairness_value_distribution_box(self, filt=False):\n",
    "        bdf = self.data_multi.get_clean_data(agg=2, drop_none=False)\n",
    "        if filt:\n",
    "            bdf = bdf[(bdf[\"ass_viol\"]==0)]\n",
    "        bdf[\"Normalised Fairness\"] = bdf[\"fair_val\"] / bdf[\"threshold\"]\n",
    "        bdf[\"Violated\"] = bdf[\"Normalised Fairness\"] > 1\n",
    "        pdf = self.data_multi.rename_data(bdf)\n",
    "        rn = self.data_multi.true_name\n",
    "        g = sns.catplot(kind=\"boxen\", data=pdf,  y=\"Normalised Fairness\" , aspect=1.2\n",
    "                        ,x =rn(\"shield\"), hue=rn(\"period\"), col=rn(\"fairness\"),log_scale=True, \n",
    "                        order=self.get_shield_order(True),\n",
    "                       col_order=[self.data_multi.fairmap[\"dp\"], self.data_multi.fairmap[\"eo\"]])\n",
    "        for ax in g.axes.flat:\n",
    "            ax.axhline(y=1, color='red', linestyle='--')\n",
    "        plt.savefig(os.path.join(self.base_path, f\"multi_violation_distr_box_cond-{filt}.pdf\"),  bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    # Plot Fig 7 and 8 but the true distribution. \n",
    "    def single_comp_conditional_utility_kde(self):\n",
    "        bdf = self.data_single.get_clean_data(agg=1, drop_none=False)\n",
    "        pdf = self.data_single.rename_data(bdf)\n",
    "        rn = self.data_single.true_name\n",
    "        sns.displot(kind=\"kde\",data=pdf, x=rn(\"diff_util\"),   hue=rn(\"ml_algo\") ,row=rn(\"threshold\"),col=rn(\"fairness\"), \n",
    "                    facet_kws={'sharey': False, 'sharex': False}, aspect=1.2) \n",
    "        plt.savefig(os.path.join(self.base_path, f\"single_utilit_distr_mlalgo_kde.pdf\"),  bbox_inches='tight', pad_inches=0.1)\n",
    "        sns.displot(kind=\"kde\",data=pdf, x=rn(\"diff_util\"),   hue=rn(\"environment\") ,\n",
    "                    row=rn(\"threshold\"),col=rn(\"fairness\"), facet_kws={'sharey': False, 'sharex': False}, aspect=1.2) \n",
    "        plt.savefig(os.path.join(self.base_path, f\"single_utilit_distr_enviornment_kde.pdf\"),  bbox_inches='tight', pad_inches=0.1)\n",
    "        \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3468b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce_experiments():\n",
    "    ana = Analyse()\n",
    "    ana.load_data()\n",
    "    ana.process_both()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566bffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reproduce_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e06661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b294d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316adf13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70e8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa791bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
